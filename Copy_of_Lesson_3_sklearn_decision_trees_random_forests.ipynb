{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarryDeCicco/AARUG-Presentation-2022_10_18/blob/main/Copy_of_Lesson_3_sklearn_decision_trees_random_forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-drain",
      "metadata": {
        "id": "acquired-drain"
      },
      "source": [
        "# Decision Trees and Random Forests - Machine Learning with Python\n",
        "\n",
        "This tutorial is a part of [Zero to Data Science Bootcamp by Jovian](https://zerotodatascience.com) and [Machine Learning with Python: Zero to GBMs](https://jovian.ai/learn/machine-learning-with-python-zero-to-gbms)\n",
        "\n",
        "![](https://i.imgur.com/N8aIuRK.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "homeless-journey",
      "metadata": {
        "id": "homeless-journey"
      },
      "source": [
        "The following topics are covered in this tutorial:\n",
        "\n",
        "- Downloading a real-world dataset\n",
        "- Preparing a dataset for training\n",
        "- Training and interpreting decision trees\n",
        "- Training and interpreting random forests\n",
        "- Overfitting, hyperparameter tuning & regularization\n",
        "- Making predictions on single inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "still-minnesota",
      "metadata": {
        "id": "still-minnesota"
      },
      "source": [
        "### How to run the code\n",
        "\n",
        "This tutorial is an executable [Jupyter notebook](https://jupyter.org) hosted on [Jovian](https://www.jovian.ai). You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.\n",
        "\n",
        "#### Option 1: Running using free online resources (1-click, recommended)\n",
        "\n",
        "The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Colab**. You will be prompted to connect your Google Drive account so that this notebook can be placed into your drive for execution.\n",
        "\n",
        "\n",
        "#### Option 2: Running on your computer locally\n",
        "\n",
        "To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "minus-perry",
      "metadata": {
        "id": "minus-perry"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "This tutorial takes a practical and coding-focused approach. We'll learn how to use _decision trees_ and _random forests_ to solve a real-world problem from [Kaggle](https://kaggle.com/datasets):\n",
        "\n",
        "> **QUESTION**: The [Rain in Australia dataset](https://kaggle.com/jsphyg/weather-dataset-rattle-package) contains about 10 years of daily weather observations from numerous Australian weather stations. Here's a small sample from the dataset:\n",
        ">\n",
        "> ![](https://i.imgur.com/5QNJvir.png)\n",
        ">\n",
        "> As a data scientist at the Bureau of Meteorology, you are tasked with creating a fully-automated system that can use today's weather data for a given location to predict whether it will rain at the location tomorrow.\n",
        ">\n",
        ">\n",
        "> ![](https://i.imgur.com/KWfcpcO.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tracked-transcript",
      "metadata": {
        "id": "tracked-transcript"
      },
      "source": [
        "Let's install and import some required libraries before we begin."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install opendatasets\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install sklearn\n",
        "\n",
        "# !pip install opendatasets pandas numpy sklearn  --quiet  # removed 'jovian'"
      ],
      "metadata": {
        "id": "MGhjOPP_Do4z"
      },
      "id": "MGhjOPP_Do4z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "palestinian-progressive",
      "metadata": {
        "id": "palestinian-progressive"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "# import jovian\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 150)\n",
        "sns.set_style('darkgrid')\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
        "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crude-tradition",
      "metadata": {
        "id": "crude-tradition"
      },
      "source": [
        "## Downloading the Data\n",
        "\n",
        "The dataset is available at https://www.kaggle.com/jsphyg/weather-dataset-rattle-package .\n",
        "\n",
        "\n",
        "We'll use the [`opendatasets` library](https://github.com/JovianML/opendatasets) to download the data from Kaggle directly within Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "passive-danger",
      "metadata": {
        "id": "passive-danger"
      },
      "outputs": [],
      "source": [
        "od.download('https://www.kaggle.com/jsphyg/weather-dataset-rattle-package')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "spiritual-guidance",
      "metadata": {
        "id": "spiritual-guidance"
      },
      "source": [
        "The dataset is downloaded and extracted to the folder `weather-dataset-rattle-package`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "invisible-oasis",
      "metadata": {
        "id": "invisible-oasis"
      },
      "outputs": [],
      "source": [
        "os.listdir('weather-dataset-rattle-package')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extra-arthritis",
      "metadata": {
        "id": "extra-arthritis"
      },
      "source": [
        "The file `weatherAUS.csv` contains the data. Let's load it into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "friendly-milan",
      "metadata": {
        "id": "friendly-milan"
      },
      "outputs": [],
      "source": [
        "raw_df = pd.read_csv('weather-dataset-rattle-package/weatherAUS.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "romantic-idaho",
      "metadata": {
        "id": "romantic-idaho"
      },
      "outputs": [],
      "source": [
        "raw_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beneficial-glass",
      "metadata": {
        "id": "beneficial-glass"
      },
      "source": [
        "Each row shows the measurements for a given date at a given location. The last column \"RainTomorrow\" contains the value to be predicted.\n",
        "\n",
        "Let's check the column types of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nominated-incidence",
      "metadata": {
        "id": "nominated-incidence"
      },
      "outputs": [],
      "source": [
        "raw_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "digital-saying",
      "metadata": {
        "id": "digital-saying"
      },
      "source": [
        "\n",
        "\n",
        "Let's drop any rows where the value of the target column `RainTomorrow` in empty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "silent-potter",
      "metadata": {
        "id": "silent-potter"
      },
      "outputs": [],
      "source": [
        "raw_df.dropna(subset=['RainTomorrow'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "charged-waste",
      "metadata": {
        "id": "charged-waste"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clean-testimony",
      "metadata": {
        "id": "clean-testimony"
      },
      "source": [
        "> **EXERCISE**: Perform exploratory data analysis on the dataset and study the relationship of other columns with the `RainTomorrow` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "objective-fifteen",
      "metadata": {
        "id": "objective-fifteen"
      },
      "outputs": [],
      "source": [
        "#Install the below libaries before importing\n",
        "# import pandas as pd\n",
        "\n",
        "!pip install ydata_profiling  --quiet\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "type(raw_df)\n",
        "#EDA using pandas-profiling\n",
        "profile = ProfileReport(raw_df, explorative=True)\n",
        "\n",
        "#Saving results to a HTML file\n",
        "profile.to_file(\"output_eda_raw_df.html\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "184b2d5e"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('output_eda_raw_df.html')"
      ],
      "id": "184b2d5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyxxJKBGUUmN"
      },
      "id": "EyxxJKBGUUmN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4aa951c"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "print(f\"Current working directory: {current_directory}\")\n",
        "\n",
        "# List files in the current directory to confirm the HTML file's presence\n",
        "print(\"Files in current directory:\")\n",
        "for item in os.listdir(current_directory):\n",
        "    if 'html' in item:\n",
        "        print(item)\n",
        "\n",
        "# Check if the specific HTML file exists\n",
        "html_file_path = './output_eda_raw_df.html'\n",
        "if os.path.exists(html_file_path):\n",
        "    print(f\"The file '{html_file_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The file '{html_file_path}' does NOT exist.\")"
      ],
      "id": "e4aa951c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e142cd9"
      },
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "# Display the generated HTML report\n",
        "IFrame(src='/content/output_eda_raw_df.html', width=900, height=600)\n",
        "\n",
        "/content/output_eda_raw_df.html"
      ],
      "id": "6e142cd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open and Display Summary Report 'output_eda_raw_df.html'\n"
      ],
      "metadata": {
        "id": "rrjiq_JsO3OX"
      },
      "id": "rrjiq_JsO3OX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ed43749"
      },
      "source": [
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "print(f\"Current working directory: {current_directory}\")\n",
        "\n",
        "# List files in the current directory to confirm the HTML file's presence\n",
        "print(\"Files in current directory:\")\n",
        "for item in os.listdir(current_directory):\n",
        "    if 'html' in item:\n",
        "        print(item)\n",
        "\n",
        "# Check if the specific HTML file exists\n",
        "html_file_path = './output_eda_raw_df.html'\n",
        "if os.path.exists(html_file_path):\n",
        "    print(f\"The file '{html_file_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The file '{html_file_path}' does NOT exist.\")"
      ],
      "id": "3ed43749",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "# Display the generated HTML report\n",
        "IFrame(src='www.google.com', width=900, height=600)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GzexBz_TPkh6"
      },
      "id": "GzexBz_TPkh6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "african-model",
      "metadata": {
        "id": "african-model"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "defined-alignment",
      "metadata": {
        "id": "defined-alignment"
      },
      "source": [
        "## Preparing the Data for Training\n",
        "\n",
        "We'll perform the following steps to prepare the dataset for training:\n",
        "\n",
        "1. Create a train/test/validation split\n",
        "2. Identify input and target columns\n",
        "3. Identify numeric and categorical columns\n",
        "4. Impute (fill) missing numeric values\n",
        "5. Scale numeric values to the $(0, 1)$ range\n",
        "6. Encode categorical columns to one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "robust-bishop",
      "metadata": {
        "id": "robust-bishop"
      },
      "source": [
        "### Training, Validation and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extensive-contractor",
      "metadata": {
        "id": "extensive-contractor"
      },
      "outputs": [],
      "source": [
        "plt.title('No. of Rows per Year')\n",
        "sns.countplot(x=pd.to_datetime(raw_df.Date).dt.year);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ignored-screw",
      "metadata": {
        "id": "ignored-screw"
      },
      "source": [
        "While working with chronological data, it's often a good idea to separate the training, validation and test sets with time, so that the model is trained on data from the past and evaluated on data from the future.\n",
        "\n",
        "We'll use the data till 2014 for the training set, data from 2015 for the validation set, and the data from 2016 & 2017 for the test set.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sharing-contract",
      "metadata": {
        "id": "sharing-contract"
      },
      "outputs": [],
      "source": [
        "year = pd.to_datetime(raw_df.Date).dt.year\n",
        "\n",
        "train_df = raw_df[year < 2015]\n",
        "val_df = raw_df[year == 2015]\n",
        "test_df = raw_df[year > 2015]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "potential-canal",
      "metadata": {
        "id": "potential-canal"
      },
      "outputs": [],
      "source": [
        "print('train_df.shape :', train_df.shape)\n",
        "print('val_df.shape :', val_df.shape)\n",
        "print('test_df.shape :', test_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "anonymous-cleaner",
      "metadata": {
        "id": "anonymous-cleaner"
      },
      "source": [
        "> **EXERCISE**: Scrape climate data for recent years (2017 to 2021) from http://www.bom.gov.au/climate/data and try training a model with the enlarged dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dominant-indian",
      "metadata": {
        "id": "dominant-indian"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "supposed-spanish",
      "metadata": {
        "id": "supposed-spanish"
      },
      "source": [
        "### Input and Target Columns\n",
        "\n",
        "Let's identify the input and target columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inside-criminal",
      "metadata": {
        "id": "inside-criminal"
      },
      "outputs": [],
      "source": [
        "input_cols = list(train_df.columns)[1:-1]\n",
        "target_col = 'RainTomorrow'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "circular-ministry",
      "metadata": {
        "id": "circular-ministry"
      },
      "outputs": [],
      "source": [
        "train_inputs = train_df[input_cols].copy()\n",
        "train_targets = train_df[target_col].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "northern-entrance",
      "metadata": {
        "id": "northern-entrance"
      },
      "outputs": [],
      "source": [
        "val_inputs = val_df[input_cols].copy()\n",
        "val_targets = val_df[target_col].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "korean-service",
      "metadata": {
        "id": "korean-service"
      },
      "outputs": [],
      "source": [
        "test_inputs = test_df[input_cols].copy()\n",
        "test_targets = test_df[target_col].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "occupational-geneva",
      "metadata": {
        "id": "occupational-geneva"
      },
      "source": [
        "Let's also identify the numeric and categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inner-prince",
      "metadata": {
        "id": "inner-prince"
      },
      "outputs": [],
      "source": [
        "numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols = train_inputs.select_dtypes('object').columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "atomic-definition",
      "metadata": {
        "id": "atomic-definition"
      },
      "outputs": [],
      "source": [
        "print(numeric_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suited-component",
      "metadata": {
        "id": "suited-component"
      },
      "outputs": [],
      "source": [
        "print(categorical_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "boxed-guarantee",
      "metadata": {
        "id": "boxed-guarantee"
      },
      "source": [
        "> **EXERCISE**: Study how various columns are correlated with the target and select just a subset of the columns, instead of all of the. Observe how it affects the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "curious-persian",
      "metadata": {
        "id": "curious-persian"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "considered-output",
      "metadata": {
        "id": "considered-output"
      },
      "source": [
        "### Imputing missing numeric values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "returning-albany",
      "metadata": {
        "id": "returning-albany"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legal-wichita",
      "metadata": {
        "id": "legal-wichita"
      },
      "outputs": [],
      "source": [
        "imputer = SimpleImputer(strategy = 'mean').fit(raw_df[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "genetic-robin",
      "metadata": {
        "id": "genetic-robin"
      },
      "outputs": [],
      "source": [
        "train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols])\n",
        "val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols])\n",
        "test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "atmospheric-orientation",
      "metadata": {
        "id": "atmospheric-orientation"
      },
      "outputs": [],
      "source": [
        "test_inputs[numeric_cols].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dense-singapore",
      "metadata": {
        "id": "dense-singapore"
      },
      "source": [
        "> **EXERCISE**: Try a different [imputation strategy](https://scikit-learn.org/stable/modules/impute.html#impute) and observe how it affects the results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scheduled-binding",
      "metadata": {
        "id": "scheduled-binding"
      },
      "source": [
        "### Scaling Numeric Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "secure-japanese",
      "metadata": {
        "id": "secure-japanese"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mechanical-quebec",
      "metadata": {
        "id": "mechanical-quebec"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler().fit(raw_df[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exciting-tonight",
      "metadata": {
        "id": "exciting-tonight"
      },
      "outputs": [],
      "source": [
        "train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])\n",
        "val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])\n",
        "test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alleged-modeling",
      "metadata": {
        "id": "alleged-modeling"
      },
      "outputs": [],
      "source": [
        "val_inputs.describe().loc[['min', 'max']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "minimal-latino",
      "metadata": {
        "id": "minimal-latino"
      },
      "source": [
        "> **EXERCISE**: Try a different [scaling strategy](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling) and observe how it affects the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "given-magnet",
      "metadata": {
        "id": "given-magnet"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "objective-conversion",
      "metadata": {
        "id": "objective-conversion"
      },
      "source": [
        "### Encoding Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "forced-video",
      "metadata": {
        "id": "forced-video"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "equal-caution",
      "metadata": {
        "id": "equal-caution"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(raw_df[categorical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "golden-soccer",
      "metadata": {
        "id": "golden-soccer"
      },
      "outputs": [],
      "source": [
        "encoded_cols = list(encoder.get_feature_names(categorical_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "finnish-cable",
      "metadata": {
        "id": "finnish-cable"
      },
      "outputs": [],
      "source": [
        "train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
        "val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
        "test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prime-package",
      "metadata": {
        "id": "prime-package"
      },
      "outputs": [],
      "source": [
        "test_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "removable-racing",
      "metadata": {
        "id": "removable-racing"
      },
      "source": [
        "> **EXERCISE**: Try a different [encoding strategy](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) and observe how it affects the results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incorporated-preliminary",
      "metadata": {
        "id": "incorporated-preliminary"
      },
      "source": [
        "As a final step, let's drop the textual categorical columns, so that we're left with just numeric data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "young-palace",
      "metadata": {
        "id": "young-palace"
      },
      "outputs": [],
      "source": [
        "X_train = train_inputs[numeric_cols + encoded_cols]\n",
        "X_val = val_inputs[numeric_cols + encoded_cols]\n",
        "X_test = test_inputs[numeric_cols + encoded_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extensive-jersey",
      "metadata": {
        "id": "extensive-jersey"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "touched-consultancy",
      "metadata": {
        "id": "touched-consultancy"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manual-halloween",
      "metadata": {
        "id": "manual-halloween"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "turned-aerospace",
      "metadata": {
        "id": "turned-aerospace"
      },
      "source": [
        "## Training and Visualizing Decision Trees\n",
        "\n",
        "A decision tree in general parlance represents a hierarchical series of binary decisions:\n",
        "\n",
        "<img src=\"https://i.imgur.com/qSH4lqz.png\" width=\"480\">\n",
        "\n",
        "A decision tree in machine learning works in exactly the same way, and except that we let the computer figure out the optimal structure & hierarchy of decisions, instead of coming up with criteria manually."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intellectual-welcome",
      "metadata": {
        "id": "intellectual-welcome"
      },
      "source": [
        "### Training\n",
        "\n",
        "We can use `DecisionTreeClassifier` from `sklearn.tree` to train a decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "central-fraction",
      "metadata": {
        "id": "central-fraction"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-martial",
      "metadata": {
        "id": "hidden-martial"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pacific-rotation",
      "metadata": {
        "id": "pacific-rotation"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "limited-destination",
      "metadata": {
        "id": "limited-destination"
      },
      "source": [
        "An optimal decision tree has now been created using the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "surprising-triumph",
      "metadata": {
        "id": "surprising-triumph"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Let's evaluate the decision tree using the accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "strategic-seven",
      "metadata": {
        "id": "strategic-seven"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "satisfactory-updating",
      "metadata": {
        "id": "satisfactory-updating"
      },
      "outputs": [],
      "source": [
        "train_preds = model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "running-bones",
      "metadata": {
        "id": "running-bones"
      },
      "outputs": [],
      "source": [
        "train_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stone-series",
      "metadata": {
        "id": "stone-series"
      },
      "outputs": [],
      "source": [
        "pd.value_counts(train_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "russian-encyclopedia",
      "metadata": {
        "id": "russian-encyclopedia"
      },
      "source": [
        "The decision tree also returns probabilities for each prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "parallel-skirt",
      "metadata": {
        "id": "parallel-skirt"
      },
      "outputs": [],
      "source": [
        "train_probs = model.predict_proba(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unique-tourist",
      "metadata": {
        "id": "unique-tourist"
      },
      "outputs": [],
      "source": [
        "train_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "equal-fisher",
      "metadata": {
        "id": "equal-fisher"
      },
      "source": [
        "Seems like the decision tree is quite confident about its predictions.\n",
        "\n",
        "Let's check the accuracy of its predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "floppy-ridge",
      "metadata": {
        "id": "floppy-ridge"
      },
      "outputs": [],
      "source": [
        "accuracy_score(train_targets, train_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "complete-poetry",
      "metadata": {
        "id": "complete-poetry"
      },
      "source": [
        "The training set accuracy is close to 100%! But we can't rely solely on the training set accuracy, we must evaluate the model on the validation set too.\n",
        "\n",
        "We can make predictions and compute accuracy in one step using `model.score`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "straight-brake",
      "metadata": {
        "id": "straight-brake"
      },
      "outputs": [],
      "source": [
        "model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "worth-parade",
      "metadata": {
        "id": "worth-parade"
      },
      "source": [
        "Although the training accuracy is 100%, the accuracy on the validation set is just about 79%, which is only marginally better then always predicting \"No\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wrapped-protection",
      "metadata": {
        "id": "wrapped-protection"
      },
      "outputs": [],
      "source": [
        "val_targets.value_counts() / len(val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "valuable-artist",
      "metadata": {
        "id": "valuable-artist"
      },
      "source": [
        "It appears that the model has learned the training examples perfect, and doesn't generalize well to previously unseen examples. This phenomenon is called \"overfitting\", and reducing overfitting is one of the most important parts of any machine learning project."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "featured-forum",
      "metadata": {
        "id": "featured-forum"
      },
      "source": [
        "### Visualization\n",
        "\n",
        "We can visualize the decision tree _learned_ from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thrown-essay",
      "metadata": {
        "id": "thrown-essay"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree, export_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accomplished-sunday",
      "metadata": {
        "id": "accomplished-sunday"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(80,20))\n",
        "plot_tree(model, feature_names=X_train.columns, max_depth=2, filled=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "naughty-horizon",
      "metadata": {
        "id": "naughty-horizon"
      },
      "source": [
        "Can you see how the model classifies a given input as a series of decisions? The tree is truncated here, but following any path from the root node down to a leaf will result in \"Yes\" or \"No\". Do you see how a decision tree differs from a logistic regression model?\n",
        "\n",
        "\n",
        "**How a Decision Tree is Created**\n",
        "\n",
        "Note the `gini` value in each box. This is the loss function used by the decision tree to decide which column should be used for splitting the data, and at what point the column should be split. A lower Gini index indicates a better split. A perfect split (only one class on each side) has a Gini index of 0.\n",
        "\n",
        "For a mathematical discussion of the Gini Index, watch this video: https://www.youtube.com/watch?v=-W0DnxQK1Eo . It has the following formula:\n",
        "\n",
        "<img src=\"https://i.imgur.com/CSC0gAo.png\" width=\"240\">\n",
        "\n",
        "Conceptually speaking, while training the models evaluates all possible splits across all possible columns and picks the best one. Then, it recursively performs an optimal split for the two portions. In practice, however, it's very inefficient to check all possible splits, so the model uses a heuristic (predefined strategy) combined with some randomization.\n",
        "\n",
        "The iterative approach of the machine learning workflow in the case of a decision tree involves growing the tree layer-by-layer:\n",
        "\n",
        "<img src=\"https://www.deepnetts.com/blog/wp-content/uploads/2019/02/SupervisedLearning.png\" width=\"480\">\n",
        "\n",
        "\n",
        "Let's check the depth of the tree that was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "horizontal-setup",
      "metadata": {
        "id": "horizontal-setup"
      },
      "outputs": [],
      "source": [
        "model.tree_.max_depth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "joined-soviet",
      "metadata": {
        "id": "joined-soviet"
      },
      "source": [
        "We can also display the tree as text, which can be easier to follow for deeper trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "charged-ireland",
      "metadata": {
        "scrolled": false,
        "id": "charged-ireland"
      },
      "outputs": [],
      "source": [
        "tree_text = export_text(model, max_depth=10, feature_names=list(X_train.columns))\n",
        "print(tree_text[:5000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "active-citizenship",
      "metadata": {
        "id": "active-citizenship"
      },
      "source": [
        "> **EXERCISE**: Based on the above discussion, can you explain why the training accuracy is 100% whereas the validation accuracy is lower?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "international-depth",
      "metadata": {
        "id": "international-depth"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "designing-model",
      "metadata": {
        "id": "designing-model"
      },
      "source": [
        "### Feature Importance\n",
        "\n",
        "Based on the gini index computations, a decision tree assigns an \"importance\" value to each feature. These values can be used to interpret the results given by a decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "frank-memorial",
      "metadata": {
        "id": "frank-memorial"
      },
      "outputs": [],
      "source": [
        "model.feature_importances_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "subsequent-lawrence",
      "metadata": {
        "id": "subsequent-lawrence"
      },
      "source": [
        "Let's turn this into a dataframe and visualize the most important features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collect-medicine",
      "metadata": {
        "id": "collect-medicine"
      },
      "outputs": [],
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inner-chorus",
      "metadata": {
        "id": "inner-chorus"
      },
      "outputs": [],
      "source": [
        "importance_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worth-stand",
      "metadata": {
        "id": "worth-stand"
      },
      "outputs": [],
      "source": [
        "plt.title('Feature Importance')\n",
        "sns.barplot(data=importance_df.head(10), x='importance', y='feature');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "federal-journalist",
      "metadata": {
        "id": "federal-journalist"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "raising-vietnamese",
      "metadata": {
        "id": "raising-vietnamese"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ahead-specific",
      "metadata": {
        "id": "ahead-specific"
      },
      "source": [
        "## Hyperparameter Tuning and Overfitting\n",
        "\n",
        "As we saw in the previous section, our decision tree classifier memorized all training examples, leading to a 100% training accuracy, while the validation accuracy was only marginally better than a dumb baseline model. This phenomenon is called overfitting, and in this section, we'll look at some strategies for reducing overfitting.\n",
        "\n",
        "The `DecisionTreeClassifier` accepts several arguments, some of which can be modified to reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "identified-assistant",
      "metadata": {
        "id": "identified-assistant"
      },
      "outputs": [],
      "source": [
        "?DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fabulous-rachel",
      "metadata": {
        "id": "fabulous-rachel"
      },
      "source": [
        "These arguments are called hyperparameters because they must be configured manually (as opposed to the parameters within the model which are _learned_ from the data. We'll explore a couple of hyperparameters:\n",
        "\n",
        "- `max_depth`\n",
        "- `max_leaf_nodes`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standard-parks",
      "metadata": {
        "id": "standard-parks"
      },
      "source": [
        "### `max_depth`\n",
        "\n",
        "By reducing the maximum depth of the decision tree, we can prevent the tree from memorizing all training examples, which may lead to better generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ready-multimedia",
      "metadata": {
        "id": "ready-multimedia"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(max_depth=3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "handmade-tactics",
      "metadata": {
        "id": "handmade-tactics"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "elementary-jimmy",
      "metadata": {
        "id": "elementary-jimmy"
      },
      "source": [
        "We can compute the accuracy of the model on the training and validation sets using `model.score`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dried-expression",
      "metadata": {
        "id": "dried-expression"
      },
      "outputs": [],
      "source": [
        "model.score(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "western-bryan",
      "metadata": {
        "id": "western-bryan"
      },
      "outputs": [],
      "source": [
        "model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "violent-design",
      "metadata": {
        "id": "violent-design"
      },
      "source": [
        "Great, while the training accuracy of the model has gone down, the validation accuracy of the model has increased significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worthy-accident",
      "metadata": {
        "id": "worthy-accident"
      },
      "outputs": [],
      "source": [
        "model.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "conscious-union",
      "metadata": {
        "id": "conscious-union"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(80,20))\n",
        "plot_tree(model, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "municipal-finger",
      "metadata": {
        "id": "municipal-finger"
      },
      "source": [
        "> **EXERCISE**: Study the decision tree diagram carefully and understand what each of the terms `gini`, `samples`, `value` and `class` mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "traditional-compiler",
      "metadata": {
        "id": "traditional-compiler"
      },
      "outputs": [],
      "source": [
        "print(export_text(model, feature_names=list(X_train.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compound-tissue",
      "metadata": {
        "id": "compound-tissue"
      },
      "source": [
        "Let's experiment with different depths using a helper function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "micro-humidity",
      "metadata": {
        "id": "micro-humidity"
      },
      "outputs": [],
      "source": [
        "def max_depth_error(md):\n",
        "    model = DecisionTreeClassifier(max_depth=md, random_state=42)\n",
        "    model.fit(X_train, train_targets)\n",
        "    train_acc = 1 - model.score(X_train, train_targets)\n",
        "    val_acc = 1 - model.score(X_val, val_targets)\n",
        "    return {'Max Depth': md, 'Training Error': train_acc, 'Validation Error': val_acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spatial-check",
      "metadata": {
        "id": "spatial-check"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "errors_df = pd.DataFrame([max_depth_error(md) for md in range(1, 21)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "higher-apparel",
      "metadata": {
        "id": "higher-apparel"
      },
      "outputs": [],
      "source": [
        "errors_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "third-banner",
      "metadata": {
        "id": "third-banner"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(errors_df['Max Depth'], errors_df['Training Error'])\n",
        "plt.plot(errors_df['Max Depth'], errors_df['Validation Error'])\n",
        "plt.title('Training vs. Validation Error')\n",
        "plt.xticks(range(0,21, 2))\n",
        "plt.xlabel('Max. Depth')\n",
        "plt.ylabel('Prediction Error (1 - Accuracy)')\n",
        "plt.legend(['Training', 'Validation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "opened-steps",
      "metadata": {
        "id": "opened-steps"
      },
      "source": [
        "This is a common pattern you'll see with all machine learning algorithms:\n",
        "\n",
        "<img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"480\">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extreme-mentor",
      "metadata": {
        "id": "extreme-mentor"
      },
      "source": [
        "You'll often need to tune hyperparameters carefully to find the optimal fit. In the above case, it appears that a maximum depth of 7 results in the lowest validation error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecological-gates",
      "metadata": {
        "id": "ecological-gates"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(max_depth=7, random_state=42).fit(X_train, train_targets)\n",
        "model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "italic-maine",
      "metadata": {
        "id": "italic-maine"
      },
      "source": [
        "### `max_leaf_nodes`\n",
        "\n",
        "Another way to control the size of complexity of a decision tree is to limit the number of leaf nodes. This allows branches of the tree to have varying depths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continent-velvet",
      "metadata": {
        "id": "continent-velvet"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(max_leaf_nodes=128, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "possible-cabinet",
      "metadata": {
        "id": "possible-cabinet"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "genetic-grammar",
      "metadata": {
        "id": "genetic-grammar"
      },
      "outputs": [],
      "source": [
        "model.score(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inclusive-organizer",
      "metadata": {
        "id": "inclusive-organizer"
      },
      "outputs": [],
      "source": [
        "model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "respiratory-tolerance",
      "metadata": {
        "id": "respiratory-tolerance"
      },
      "outputs": [],
      "source": [
        "model.tree_.max_depth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invisible-jones",
      "metadata": {
        "id": "invisible-jones"
      },
      "source": [
        "Notice that the model was able to achieve a greater depth of 12 for certain paths while keeping other paths shorter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "polar-failure",
      "metadata": {
        "id": "polar-failure"
      },
      "outputs": [],
      "source": [
        "model_text = export_text(model, feature_names=list(X_train.columns))\n",
        "print(model_text[:3000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noble-connectivity",
      "metadata": {
        "id": "noble-connectivity"
      },
      "source": [
        "> **EXERCISE**: Find the combination of `max_depth` and `max_leaf_nodes` that results in the highest validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "impossible-container",
      "metadata": {
        "id": "impossible-container"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "applicable-brazilian",
      "metadata": {
        "id": "applicable-brazilian"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "swedish-flooring",
      "metadata": {
        "id": "swedish-flooring"
      },
      "source": [
        "> **EXERCISE**: Explore and experiment with other arguments of `DecisionTree`. Refer to the docs for details: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "third-maker",
      "metadata": {
        "id": "third-maker"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "static-harassment",
      "metadata": {
        "id": "static-harassment"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "decimal-gossip",
      "metadata": {
        "id": "decimal-gossip"
      },
      "source": [
        "> **EXERCISE**: A more advanced technique (but less commonly used technique) for reducing overfitting in decision trees is known as cost-complexity pruning. Learn more about it here: https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html . Implement cost complexity pruning. Do you see any improvement in the validation accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "proud-clear",
      "metadata": {
        "id": "proud-clear"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ignored-lottery",
      "metadata": {
        "id": "ignored-lottery"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bibliographic-growth",
      "metadata": {
        "id": "bibliographic-growth"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boring-custody",
      "metadata": {
        "id": "boring-custody"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "civic-terrain",
      "metadata": {
        "id": "civic-terrain"
      },
      "source": [
        "## Training a Random Forest\n",
        "\n",
        "While tuning the hyperparameters of a single decision tree may lead to some improvements, a much more effective strategy is to combine the results of several decision trees trained with slightly different parameters. This is called a random forest.\n",
        "\n",
        "The key idea here is that each decision tree in the forest will make different kinds of errors, and upon averaging, many of their errors will cancel out. This idea is also known as the \"wisdom of the crowd\" in common parlance:\n",
        "\n",
        "<img src=\"https://i.imgur.com/4Dg0XK4.png\" width=\"480\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "legendary-persian",
      "metadata": {
        "id": "legendary-persian"
      },
      "source": [
        "A random forest works by averaging/combining the results of several decision trees:\n",
        "\n",
        "<img src=\"https://1.bp.blogspot.com/-Ax59WK4DE8w/YK6o9bt_9jI/AAAAAAAAEQA/9KbBf9cdL6kOFkJnU39aUn4m8ydThPenwCLcBGAsYHQ/s0/Random%2BForest%2B03.gif\" width=\"640\">\n",
        "\n",
        "\n",
        "We'll use the `RandomForestClassifier` class from `sklearn.ensemble`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "asian-latvia",
      "metadata": {
        "id": "asian-latvia"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "corrected-plate",
      "metadata": {
        "id": "corrected-plate"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "controversial-voice",
      "metadata": {
        "id": "controversial-voice"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "capital-blake",
      "metadata": {
        "id": "capital-blake"
      },
      "outputs": [],
      "source": [
        "model.score(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "second-failing",
      "metadata": {
        "id": "second-failing"
      },
      "outputs": [],
      "source": [
        "model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coral-belize",
      "metadata": {
        "id": "coral-belize"
      },
      "source": [
        "Once again, the training accuracy is 100%, but this time the validation accuracy is much better. In fact, it is better than the best single decision tree we had trained so far. Do you see the power of random forests?\n",
        "\n",
        "This general technique of combining the results of many models is called \"ensembling\", it works because most errors of individual models cancel out on averaging. Here's what it looks like visually:\n",
        "\n",
        "<img src=\"https://i.imgur.com/qJo8D8b.png\" width=\"480\">\n",
        "\n",
        "\n",
        "We can also look at the probabilities for the predictions. The probability of a class is simply the fraction of trees which that predicted the given class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rapid-corpus",
      "metadata": {
        "id": "rapid-corpus"
      },
      "outputs": [],
      "source": [
        "train_probs = model.predict_proba(X_train)\n",
        "train_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "artistic-racing",
      "metadata": {
        "id": "artistic-racing"
      },
      "source": [
        "We can can access individual decision trees using `model.estimators_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "centered-treasure",
      "metadata": {
        "id": "centered-treasure"
      },
      "outputs": [],
      "source": [
        "model.estimators_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reflected-concept",
      "metadata": {
        "id": "reflected-concept"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(80,20))\n",
        "plot_tree(model.estimators_[0], max_depth=2, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "identical-resolution",
      "metadata": {
        "id": "identical-resolution"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(80,20))\n",
        "plot_tree(model.estimators_[15], max_depth=2, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "controlled-scheduling",
      "metadata": {
        "id": "controlled-scheduling"
      },
      "outputs": [],
      "source": [
        "len(model.estimators_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handmade-happiness",
      "metadata": {
        "id": "handmade-happiness"
      },
      "source": [
        "> **EXERCISE**: Verify that none of the individual decision trees have a better validation accuracy than the random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sharp-rotation",
      "metadata": {
        "id": "sharp-rotation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stunning-stations",
      "metadata": {
        "id": "stunning-stations"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "earned-hierarchy",
      "metadata": {
        "id": "earned-hierarchy"
      },
      "source": [
        "Just like decision tree, random forests also assign an \"importance\" to each feature, by combining the importance values from individual trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "humanitarian-maker",
      "metadata": {
        "id": "humanitarian-maker"
      },
      "outputs": [],
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hindu-shaft",
      "metadata": {
        "id": "hindu-shaft"
      },
      "outputs": [],
      "source": [
        "importance_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "split-nature",
      "metadata": {
        "id": "split-nature"
      },
      "outputs": [],
      "source": [
        "plt.title('Feature Importance')\n",
        "sns.barplot(data=importance_df.head(10), x='importance', y='feature');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wired-copper",
      "metadata": {
        "id": "wired-copper"
      },
      "source": [
        "Notice that the distribution is a lot less skewed than that for a single decision tree."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-simon",
      "metadata": {
        "id": "invalid-simon"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wicked-distance",
      "metadata": {
        "id": "wicked-distance"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "australian-ambassador",
      "metadata": {
        "id": "australian-ambassador"
      },
      "source": [
        "## Hyperparameter Tuning with Random Forests\n",
        "\n",
        "Just like decision trees, random forests also have several hyperparameters. In fact many of these hyperparameters are applied to the underlying decision trees.\n",
        "\n",
        "Let's study some the hyperparameters for random forests. You can learn more about them here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "several-basement",
      "metadata": {
        "id": "several-basement"
      },
      "outputs": [],
      "source": [
        "?RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "universal-style",
      "metadata": {
        "id": "universal-style"
      },
      "source": [
        "Let's create a base model with which we can compare models with tuned hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "toxic-bacteria",
      "metadata": {
        "id": "toxic-bacteria"
      },
      "outputs": [],
      "source": [
        "base_model = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pleased-jefferson",
      "metadata": {
        "id": "pleased-jefferson"
      },
      "outputs": [],
      "source": [
        "base_train_acc = base_model.score(X_train, train_targets)\n",
        "base_val_acc = base_model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hydraulic-individual",
      "metadata": {
        "id": "hydraulic-individual"
      },
      "outputs": [],
      "source": [
        "base_accs = base_train_acc, base_val_acc\n",
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "minute-sunrise",
      "metadata": {
        "id": "minute-sunrise"
      },
      "source": [
        "### `n_estimators`\n",
        "\n",
        "This controls the number of decision trees in the random forest. The default value is 100. For larger datasets, it helps to have a greater number of estimators. As a general rule, try to have as few estimators as needed.\n",
        "\n",
        "\n",
        "**10 estimators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "considered-occasions",
      "metadata": {
        "id": "considered-occasions"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loving-wallace",
      "metadata": {
        "scrolled": true,
        "id": "loving-wallace"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "isolated-sheriff",
      "metadata": {
        "id": "isolated-sheriff"
      },
      "outputs": [],
      "source": [
        "model.score(X_train, train_targets), model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interesting-engineering",
      "metadata": {
        "id": "interesting-engineering"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "variable-inspiration",
      "metadata": {
        "id": "variable-inspiration"
      },
      "source": [
        "**500 estimators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "australian-robin",
      "metadata": {
        "id": "australian-robin"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=500)\n",
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thorough-astronomy",
      "metadata": {
        "id": "thorough-astronomy"
      },
      "outputs": [],
      "source": [
        "model.score(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alike-friendly",
      "metadata": {
        "id": "alike-friendly"
      },
      "outputs": [],
      "source": [
        "model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "signal-attendance",
      "metadata": {
        "id": "signal-attendance"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "classified-procedure",
      "metadata": {
        "id": "classified-procedure"
      },
      "source": [
        "> **EXERCISE**: Vary the value of `n_estimators` and plot the graph between training error and validation error. What is the optimal value of `n_estimators`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olympic-morning",
      "metadata": {
        "id": "olympic-morning"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "complimentary-charles",
      "metadata": {
        "id": "complimentary-charles"
      },
      "source": [
        "### `max_features`\n",
        "\n",
        "Instead of picking all features for every split, we can specify only a fraction of features to be chosen randomly.\n",
        "\n",
        "<img src=\"https://i.imgur.com/FXGWMDY.png\" width=\"720\">\n",
        "\n",
        "Notice that the default value `auto` causes only $\\sqrt{n}$ out of total features ( $n$ ) to be chosen randomly at each split. This is the reason each decision tree is in the forest is different. While it may seem counterintuitive, choosing all features for every split of every tree will lead to identical trees, so the random forest will not generalize well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legendary-period",
      "metadata": {
        "id": "legendary-period"
      },
      "outputs": [],
      "source": [
        "test_params(max_features='log2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "satisfied-welding",
      "metadata": {
        "id": "satisfied-welding"
      },
      "outputs": [],
      "source": [
        "test_params(max_features=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "higher-simon",
      "metadata": {
        "id": "higher-simon"
      },
      "outputs": [],
      "source": [
        "test_params(max_features=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "owned-resolution",
      "metadata": {
        "id": "owned-resolution"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "charitable-catch",
      "metadata": {
        "id": "charitable-catch"
      },
      "source": [
        "> **EXERCISE**: Find the optimal values of `max_features` for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "peripheral-quarterly",
      "metadata": {
        "id": "peripheral-quarterly"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "entire-ivory",
      "metadata": {
        "id": "entire-ivory"
      },
      "source": [
        "### `max_depth` and `max_leaf_nodes`\n",
        "\n",
        "These arguments are passed directly to each decision tree, and control the maximum depth and max. no leaf nodes of each tree respectively. By default, no maximum depth is specified, which is why each tree has a training accuracy of 100%. You can specify a `max_depth` to reduce overfitting.\n",
        "\n",
        "<img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"480\">\n",
        "\n",
        "Let's define a helper function to `max depth`, `max_leaf_nodes` and other hyperparameters easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "american-plumbing",
      "metadata": {
        "id": "american-plumbing"
      },
      "outputs": [],
      "source": [
        "def test_params(**params):\n",
        "    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params).fit(X_train, train_targets)\n",
        "    return model.score(X_train, train_targets), model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "composite-mystery",
      "metadata": {
        "id": "composite-mystery"
      },
      "source": [
        "Let's test a few values of `max_depth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "latest-employer",
      "metadata": {
        "id": "latest-employer"
      },
      "outputs": [],
      "source": [
        "test_params(max_depth=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continuing-bridge",
      "metadata": {
        "id": "continuing-bridge"
      },
      "outputs": [],
      "source": [
        "test_params(max_depth=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "minimal-afghanistan",
      "metadata": {
        "id": "minimal-afghanistan"
      },
      "outputs": [],
      "source": [
        "test_params(max_leaf_nodes=2**5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worldwide-clear",
      "metadata": {
        "id": "worldwide-clear"
      },
      "outputs": [],
      "source": [
        "test_params(max_leaf_nodes=2**20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "removable-printer",
      "metadata": {
        "id": "removable-printer"
      },
      "outputs": [],
      "source": [
        "base_accs # no max depth or max leaf nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floral-flexibility",
      "metadata": {
        "id": "floral-flexibility"
      },
      "source": [
        "The optimal values of `max_depth` and `max_leaf_nodes` lies somewhere between 0 and unbounded."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "executive-inspiration",
      "metadata": {
        "id": "executive-inspiration"
      },
      "source": [
        "> **EXERCISE**: Vary the value of `max_depth` and plot the graph between training error and validation error. What is the optimal value of `max_depth`? Do the same for `max_leaf_nodes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "widespread-athens",
      "metadata": {
        "id": "widespread-athens"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "advanced-integer",
      "metadata": {
        "id": "advanced-integer"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "continuing-portal",
      "metadata": {
        "id": "continuing-portal"
      },
      "source": [
        "### `min_samples_split` and `min_samples_leaf`\n",
        "\n",
        "By default, the decision tree classifier tries to split every node that has 2 or more. You can increase the values of these arguments to change this behavior and reduce overfitting, especially for very large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unauthorized-defense",
      "metadata": {
        "id": "unauthorized-defense"
      },
      "outputs": [],
      "source": [
        "test_params(min_samples_split=3, min_samples_leaf=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organizational-kitchen",
      "metadata": {
        "id": "organizational-kitchen"
      },
      "outputs": [],
      "source": [
        "test_params(min_samples_split=100, min_samples_leaf=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "outstanding-landscape",
      "metadata": {
        "id": "outstanding-landscape"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "excellent-lending",
      "metadata": {
        "id": "excellent-lending"
      },
      "source": [
        "> **EXERCISE**: Find the optimal values of `min_samples_split` and `min_samples_leaf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "excellent-pocket",
      "metadata": {
        "id": "excellent-pocket"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "instant-effect",
      "metadata": {
        "id": "instant-effect"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "parallel-advertiser",
      "metadata": {
        "id": "parallel-advertiser"
      },
      "source": [
        "### `min_impurity_decrease`\n",
        "\n",
        "This argument is used to control the threshold for splitting nodes. A node will be split if this split induces a decrease of the impurity (Gini index) greater than or equal to this value. It's default value is 0, and you can increase it to reduce overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "furnished-september",
      "metadata": {
        "id": "furnished-september"
      },
      "outputs": [],
      "source": [
        "test_params(min_impurity_decrease=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "optional-dominican",
      "metadata": {
        "id": "optional-dominican"
      },
      "outputs": [],
      "source": [
        "test_params(min_impurity_decrease=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "champion-marsh",
      "metadata": {
        "id": "champion-marsh"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sufficient-wallpaper",
      "metadata": {
        "id": "sufficient-wallpaper"
      },
      "source": [
        "> **EXERCISE**: Find the optimal values of `min_impurity_decrease` for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-horizontal",
      "metadata": {
        "id": "short-horizontal"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "tested-jacket",
      "metadata": {
        "id": "tested-jacket"
      },
      "source": [
        "### `bootstrap`, `max_samples`\n",
        "\n",
        "By default, a random forest doesn't use the entire dataset for training each decision tree. Instead it applies a technique called bootstrapping. For each tree, rows from the dataset are picked one by one randomly, with replacement i.e. some rows may not show up at all, while some rows may show up multiple times.\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/W8UGaEA.png\" width=\"640\">\n",
        "\n",
        "Bootstrapping helps the random forest generalize better, because each decision tree only sees a fraction of th training set, and some rows randomly get higher weightage than others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "secondary-limit",
      "metadata": {
        "id": "secondary-limit"
      },
      "outputs": [],
      "source": [
        "test_params(bootstrap=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statistical-console",
      "metadata": {
        "id": "statistical-console"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-milton",
      "metadata": {
        "id": "involved-milton"
      },
      "source": [
        "When bootstrapping is enabled, you can also control the number or fraction of rows to be considered for each bootstrap using `max_samples`. This can further generalize the model.\n",
        "\n",
        "<img src=\"https://i.imgur.com/rsdrL1W.png\" width=\"640\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "chief-geography",
      "metadata": {
        "id": "chief-geography"
      },
      "outputs": [],
      "source": [
        "test_params(max_samples=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "international-spine",
      "metadata": {
        "id": "international-spine"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perfect-grave",
      "metadata": {
        "id": "perfect-grave"
      },
      "source": [
        "Learn more about bootstrapping here: https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "armed-surgeon",
      "metadata": {
        "id": "armed-surgeon"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "secure-italic",
      "metadata": {
        "id": "secure-italic"
      },
      "source": [
        "### `class_weight`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "appreciated-clerk",
      "metadata": {
        "id": "appreciated-clerk"
      },
      "outputs": [],
      "source": [
        "model.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "forced-storm",
      "metadata": {
        "id": "forced-storm"
      },
      "outputs": [],
      "source": [
        "test_params(class_weight='balanced')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "regulation-chemistry",
      "metadata": {
        "id": "regulation-chemistry"
      },
      "outputs": [],
      "source": [
        "test_params(class_weight={'No': 1, 'Yes': 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "chemical-hollywood",
      "metadata": {
        "id": "chemical-hollywood"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "married-lewis",
      "metadata": {
        "id": "married-lewis"
      },
      "source": [
        "> **EXERCISE**: Find the optimal value of `class_weight` for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pointed-outreach",
      "metadata": {
        "id": "pointed-outreach"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "historic-dominican",
      "metadata": {
        "id": "historic-dominican"
      },
      "source": [
        "### Putting it together\n",
        "\n",
        "Let's train a random forest with customized hyperparameters based on our learnings. Of course, different hyperpraams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "academic-adult",
      "metadata": {
        "id": "academic-adult"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_jobs=-1,\n",
        "                               random_state=42,\n",
        "                               n_estimators=500,\n",
        "                               max_features=7,\n",
        "                               max_depth=30,\n",
        "                               class_weight={'No': 1, 'Yes': 1.5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efficient-peripheral",
      "metadata": {
        "id": "efficient-peripheral"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sought-jones",
      "metadata": {
        "id": "sought-jones"
      },
      "outputs": [],
      "source": [
        "model.score(X_train, train_targets), model.score(X_val, val_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "satisfactory-option",
      "metadata": {
        "id": "satisfactory-option"
      },
      "outputs": [],
      "source": [
        "base_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prescription-scott",
      "metadata": {
        "id": "prescription-scott"
      },
      "source": [
        "We've increased the accuracy from 84.5% with a single decision tree to 85.7% with a well-tuned random forest. Depending on the dataset, you may or may not a see a significant improvement with hyperparameter tuning. This could be due to any of the following reasons:\n",
        "\n",
        "- There simply may not be enough signal in the dataset. Whether it will rain tomorrow is an inherently uncertain outcome, and we can't predict it accurac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sweet-coaching",
      "metadata": {
        "id": "sweet-coaching"
      },
      "outputs": [],
      "source": [
        "raw_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "editorial-performance",
      "metadata": {
        "id": "editorial-performance"
      },
      "source": [
        "> **EXERCISE**: Experiment with the hyperparameters of the random forest classifier, and try to maximize the validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continuing-transportation",
      "metadata": {
        "id": "continuing-transportation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "terminal-clock",
      "metadata": {
        "id": "terminal-clock"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "harmful-oxford",
      "metadata": {
        "id": "harmful-oxford"
      },
      "source": [
        "Let's also compute the accuracy of our final model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unknown-surface",
      "metadata": {
        "id": "unknown-surface"
      },
      "outputs": [],
      "source": [
        "model.score(X_test, test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collect-hurricane",
      "metadata": {
        "id": "collect-hurricane"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "unlike-press",
      "metadata": {
        "id": "unlike-press"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sixth-reputation",
      "metadata": {
        "id": "sixth-reputation"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "central-discretion",
      "metadata": {
        "id": "central-discretion"
      },
      "source": [
        "## Making Predictions on New Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brave-scout",
      "metadata": {
        "id": "brave-scout"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "engaging-flesh",
      "metadata": {
        "id": "engaging-flesh"
      },
      "outputs": [],
      "source": [
        "def predict_input(single_input):\n",
        "    input_df = pd.DataFrame([single_input])\n",
        "    input_df[numeric_cols] = imputer.transform(input_df[numeric_cols])\n",
        "    input_df[numeric_cols] = scaler.transform(input_df[numeric_cols])\n",
        "    input_df[encoded_cols] = encoder.transform(input_df[categorical_cols])\n",
        "    X_input = input_df[numeric_cols + encoded_cols]\n",
        "    pred = model.predict(X_input)[0]\n",
        "    prob = model.predict_proba(X_input)[0][list(model.classes_).index(pred)]\n",
        "    return pred, prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sustained-legislature",
      "metadata": {
        "id": "sustained-legislature"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "severe-vegetable",
      "metadata": {
        "id": "severe-vegetable"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "foster-framing",
      "metadata": {
        "id": "foster-framing"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "binary-monster",
      "metadata": {
        "id": "binary-monster"
      },
      "source": [
        "## Summary and References\n",
        "\n",
        "\n",
        "Important terms:\n",
        "\n",
        "* Decision tree\n",
        "* Overfitting\n",
        "* Hyperparameter\n",
        "* Regularization\n",
        "* Random forest\n",
        "* Ensembling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fourth-approach",
      "metadata": {
        "id": "fourth-approach"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}